## Tutorial 3

### Launching the GPU kernel & GPU Hierarchy
- cpu launches the kernel with n blocks and m threads per block
    - why don't we specify m threads directly?
    - thread is the smallest unit of execution.

- on launch, the gpu creates a grid, the grid contains n blocks, each block contains m threads
    - why the number of threads per block should be a multiple of 32?

- indexing the threads
    - ![](2_paint.png)
    - grids and blocks can be 1D, 2D or 3D, why?
    - blockIdx
    - threadIdx
    - why do we have index validation in the kernel?
    ![](index_validation.png) 

- gpu processor (scheduler) assigns blocks to SMs; an SM is a mini-processor with its own set of cores.
    - an SM can handle multiple blocks
    - to be discussed: with limited set of cores per SM, an SM can hold limited number of blocks, then not all blocks/threads starts execution at the same time, what happens? 
    - why does the scheduler assign the full block to one SM? (not half of a block is assigned to one SM, the other half is assigned to other SM): so the threads of the same block can communicate/ share data

- now the hierarchy is organized, and threads are ready for kernel execution

- before we get to the execution of threads on cores
    - what is the diff between a thread and a core?
    ![](thread_and_core.png)

- lets start the execution